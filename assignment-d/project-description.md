#B-MU201/PRINCIPAL STUDY 2 (MUSIC TECHNOLOGY)/AY15-16

# Assignment D for B-MU201 Principal Study
# Wong Chong Hao 16536
# http://amonmakesoriginalnoises.tumblr.com/tagged/processing

## Assignment D 
[Video](https://vimeo.com/163207128)

![image](http://40.media.tumblr.com/acd252a73eaae5f132f6b87263ee34c7/tumblr_o5tdfpH4fl1udcd6jo1_1280.png)

![image](http://41.media.tumblr.com/08a81b40eeba2953b967c4acc9ed4c2a/tumblr_o5tdfpH4fl1udcd6jo4_1280.png)

![image](http://40.media.tumblr.com/6e1c5a3d2bfb4c73d46562b322ddb434/tumblr_o5tdfpH4fl1udcd6jo5_1280.png)

![image](http://41.media.tumblr.com/03e8d94863e60002c42eb19b44bf66d9/tumblr_o5tdfpH4fl1udcd6jo8_1280.png)

 <b>”Deep” by Amon Wong</b>


# Project Description

“Deep” is a refining of my initial sketch “Woodblock” done earlier for Assignment B. It is paired with an original ambient piece titled “Past and Languages”. The piece comes from a place of anguish, being holed up in one’s room/box and a reminder of the Bible verse, Psalms 42:7 <i>“Deep Cries Out”</i>. The piece serves as a reminder to all that there is light in the darkness and that we are somehow all connected through one entire cosmos. 

“Deep” draws it’s main influences from Raven Kwok’s <i>Algorithmic Creatures</i> series, Diana Lange’s <i>Audio and Beat Detection</i> series as well as Ryoichi Kurokawa’s <i>syn.</i>. I chose to extensively study their codes, at least what I could find of it, in the process of creating “Deep” but I am proud to say that my code is completely original. 

What intrigued me about Raven Kwok’s <i>Algorithmic Creatures</i> series was the lifeforms that Kwok created. Their cellular-like behaviour was created using a series of flocking and vector algorithms, which I managed to replicate using my mouse and PeasyCam, angling it in such a way that displays complexity but yet, is easily controllable and predictable. Diana Lange’s <i>Audio and Beat Detection</i> series showed me the beauty of using lines to achieve movement. She uses beat detection to manipulate the width of her circles as well as the length of the lines, which I used as inspiration to connect my cubes using audio-reactive lines. Ryoichi Kurokawa’s <i>syn.</i> uses OpenFrameworks for his work, but what I enjoyed particularly about <i>”syn.”<i> is how the lines are mapped to individual pixels of an object and how they resemble fading toothpicks, which was something I adopted into my piece.  


# How does it work? 
The piece uses Minim to generate its audio-reactive lines. The white lines are mapped to react to frequency whereas, the yellow lines are triggered upon a spike in amplitude. PeasyCam is used to control all the camera movements. The boxes are generated at the centre of the piece and then explodes into random places in space, with  each box limited to a certain distance from each other. Midibus is paired with a keyboard for controlled glitch effects such as displacing the boxes or shifting the camera movement. 




